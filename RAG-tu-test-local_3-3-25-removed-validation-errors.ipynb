{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unclear why previous line of \"import langchain\" \n",
    "# was issued as first command; not in tutorial\n",
    "# thus converting to code marked with X\n",
    "# instructions: reference RAG tutorial at \n",
    "# https://python.langchain.com/docs/tutorials/rag/\n",
    "# attempt to run RAG on HPC and play with hyperparameters & tuning\n",
    "# below begins tutorial as command line\n",
    "\n",
    "# %pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "\n",
    "# threw terminal error, -bash: fg: %pip: no such job\n",
    "# attempted to save but connection error, even though logged in as login4.frontera(49)$ \n",
    "# building on local file herein in order to proceed\n",
    "# entered following on command line, pip install langsmith\n",
    "# threw error Collecting langsmith  \n",
    "# ERROR: Could not find a version that satisfies the requirement langsmith (from versions: none)\n",
    "# ERROR: No matching distribution found for langsmith\n",
    "# WARNING: You are using pip version 19.2.3, however version 24.0 is available.\n",
    "# You should consider upgrading via the 'pip install --upgrade pip' command.\n",
    "# upgrade attempted that upgrade 2/18/25 & Slacked Juliana screenshot of errors\n",
    "# realized I need to complete account setup, i.e., set up observability on langchain.com\n",
    "# in terminal, pip install -U langchain langchain-openai\n",
    "# Collecting langchain\n",
    "#   Downloading https://files.pythonhosted.org/packages/1f/fd/<REDACTED>/langchain-0.0.27-py3-none-any.whl (124kB)\n",
    "#      |██▋                             | 10kB 18.7MB/s eta 0:00     |█████▎                          | 20kB 4.0MB/s eta 0:00:     |███████▉                        | 30kB 5.9MB/s eta 0:00:     |██████████▌                     | 40kB 2.7MB/s eta 0:00:     |█████████████▏                  | 51kB 2.9MB/s eta 0:00:     |███████████████▊                | 61kB 3.5MB/s eta 0:00:     |██████████████████▍             | 71kB 3.5MB/s eta 0:00:     |█████████████████████           | 81kB 4.0MB/s eta 0:00:     |███████████████████████▋        | 92kB 4.3MB/s eta 0:00:     |██████████████████████████▎     | 102kB 4.4MB/s eta 0:00     |████████████████████████████▉   | 112kB 4.4MB/s eta 0:00     |███████████████████████████████▌| 122kB 4.4MB/s eta 0:00     |████████████████████████████████| 133kB 4.4MB/s \n",
    "# Collecting langchain-openai\n",
    "#   ERROR: Could not find a version that satisfies the requirement langchain-openai (from versions: none)\n",
    "# ERROR: No matching distribution found for langchain-openai\n",
    "# WARNING: You are using pip version 19.2.3, however version 24.0 is available.\n",
    "# You should consider upgrading via the 'pip install --upgrade pip' command.\n",
    "# Successfully installed pip\n",
    "# Next installation should be as follows on next line\n",
    "\n",
    "# %pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "\n",
    "# However it threw this error\n",
    "# fg: job not found: pip\n",
    "# Copilot said to remove % symbol, correct installation follows\n",
    "\n",
    "# pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "\n",
    "# nothing happened in terminal so asked copilot how to verify installation\n",
    "# said to enter as follows\n",
    "# pip show langchain-text-splitters langchain-community langgraph\n",
    "# ran and verified langchain-text-splitters\n",
    "# returning to entering RAG tutorial code\n",
    "\n",
    "# To inspect what is going on inside chain or agent, \n",
    "# sign up for LangSmith, https://smith.langchain.com/\n",
    "# Langchain prompts to set up observability with or without LangChain\n",
    "# Given having installed Langchain on terminal in above step, \n",
    "# returned to observability setup instructions; chose \"With LangChain\"\n",
    "# Click button to create key for a future instruction step \n",
    "\n",
    "# Install dependencies by typing following into terminal\n",
    "# pip install -U langchain langchain-openai\n",
    "# Confirm terminal displays successful installation\n",
    "# Return to tutorial\n",
    "\n",
    "# Configure environment to connect to LangSmith \n",
    "# by typing your own project name in the Project Name field\n",
    "# I typed the following\n",
    "# Chris Benevich RAG Tutorial Tuning Practice\n",
    "# The code generated on the LangSmith page for your notebook\n",
    "# will have the API key generated in an earlier step\n",
    "# It will also have the project name you chose\n",
    "# Before proceeding to next instruction, note that the below code\n",
    "# may require purchase of a key and thus not function.\n",
    "# This may be why I was instructed to use Hugging Face\n",
    "# for the embeddings model. \n",
    "\n",
    "# Related to this and the observability model setup above,\n",
    "# I elected to keep all models as OpenAI, as the Langchain\n",
    "# observability page required OpenAI\n",
    "# Copy the code and paste into your notebook as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUO: LANGSMITH_TRACING=true\n",
    "# SUO: LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "# SUO: LANGSMITH_API_KEY=\"<REDACTED>\"\n",
    "# SUO: LANGSMITH_PROJECT=\"Chris Benevich RAG Tutorial Practice\"\n",
    "# SUO: OPENAI_API_KEY=\"<your-openai-api-key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LLM, chat model or chain for trace to be sent \n",
    "# to this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUO: from langchain_openai import ChatOpenAI\n",
    "\n",
    "# SUO: llm = ChatOpenAI()\n",
    "# SUO: llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith page then has a button, \"Skip for now\"\n",
    "# I left that page open as a tab in the browser\n",
    "# and did not click the button\n",
    "# Separately I did not install anything else not\n",
    "# explicitly stated above, even though I found\n",
    "# a site with more packages at \n",
    "# https://python.langchain.com/docs/how_to/installation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return to RAG tutorial\n",
    "# set environment variables in notebook to log traces\n",
    "# Per Mentor, remove use of LangSmith: convert to comment preceded by X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X import getpass\n",
    "# X import os\n",
    "\n",
    "# X os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# X os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice next instruction requests selection of chat model\n",
    "# Per mentor, select small model\n",
    "# Per Copilot, 3 smallest models include OpenAI o3-mini\n",
    "# but not the version offered in the RAG tutorial\n",
    "# which is simply OpenAI\n",
    "# Notice that LangChain code above imports OpenAI\n",
    "# Thus, select OpenAI in dropdown and run below in terminal\n",
    "# pip install -qU \"langchain[openai]\"\n",
    "# Enter below in notebook\n",
    "# Convert the API & password code to a comment and \n",
    "# see if it runs as password not needed as follows\n",
    "# Convert the OpenAI chat model to comments and try AWS instead\n",
    "# Install AWS chat model as follows\n",
    "# pip install -qu \"langchain[aws]\"\n",
    "# Verify if successful with command as follows\n",
    "# pip show langchain\n",
    "# That only verified that langchain was installed\n",
    "# Next list all packages to skim for any AWS library as follows\n",
    "# pip list\n",
    "# Saw boto3 listed per Copilot statement it is an AWS library\n",
    "# Also saw langsmith listed and wonder if uninstalling\n",
    "# will remove any unnecessary dependencies\n",
    "# To uninstall langsmith type command as follows\n",
    "# pip uninstall langsmith  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X import getpass\n",
    "# X import os\n",
    "\n",
    "# X if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "# X     os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "    \n",
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "# llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"anthropic.claude-3-5-sonnet-20240620-v1:0\", model_provider=\"bedrock_converse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 2 of 3 LangChain integrations as follows\n",
    "# Select embeddings model drop-down as OpenAI\n",
    "# Run below in terminal\n",
    "# pip install -qU langchain-openai\n",
    "# Nothing appears in terminal to verify successful install\n",
    "# HPC disconnected & didn't save notebook; creating VS Code backup \n",
    "# hard drive version to upload when HPC becomes available \n",
    "# (checked Frontera, Vista & Stamp3de) \n",
    "# Return to RAG tutorial and enter below in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select OpenAI embeddings model in drop-down\n",
    "# Type below in Terminal\n",
    "# pip install -qU langchain-openai\n",
    "# Verify successful installation with below command\n",
    "# pip show langchain-openai\n",
    "# Return to RAG tutorial & enter below in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X import getpass\n",
    "# X import os\n",
    "\n",
    "# X if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "#   X   os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "# X from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# X embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use HuggingFace embeddings model, convert above code to comments &\n",
    "# mark as deleted with \"X\"\n",
    "# to document & begin documenting HuggingFace. Enter code in Terminal as follows  \n",
    "# pip install -qU langchain-huggingface\n",
    "# Verify successful installation with below command\n",
    "# pip show langchain-huggingface\n",
    "# Enter code as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select vector store in drop-down, chose AstraDB for scalability\n",
    "# Input below command in Terminal\n",
    "# pip install -qU langchain-astradb\n",
    "# Verify successful installation: input below command in Terminal\n",
    "# pip show langchain-astradb\n",
    "# Return to notebook, enter below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X from langchain_astradb import AstraDBVectorStore\n",
    "\n",
    "# X vector_store = AstraDBVectorStore(\n",
    "#   X   embedding=embeddings,\n",
    "#   X   api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "#   X   collection_name=\"astra_vector_langchain\",\n",
    "#   X   token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "#   X   namespace=ASTRA_DB_NAMESPACE,\n",
    "# X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to below troubleshooting, deleted above code &\n",
    "# converted to comment to document\n",
    "# Change vector store to Chroma with \n",
    "# command in Terminal as follows\n",
    "# pip install -qU langchain-chroma\n",
    "# Verified successful install with command in Terminal as follows\n",
    "# pip show langchain-chroma\n",
    "# Enter code as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build app that answers questions about a website's content\n",
    "# Create indexing pipeline and RAG chain\n",
    "\n",
    "# Command in Terminal as follows\n",
    "# pip install beautifulsoup4\n",
    "# Terminal autogenerated verification of successful install\n",
    "# Enter code as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and chunk contents of the blog\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index chunks\n",
    "\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt for question-answering\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state for application\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define application steps\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile application and test\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unclear what the API Reference links in the tutorial are for\n",
    "# as in, do they affect the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2/25/25 initiate test of code on local machine in Terminal\n",
    "# To obtain raw code for Terminal, opened notebook as .txt\n",
    "# Note that TextEdit will add JSON structure to the code,\n",
    "# including metadata, cell types, execution counts, and source code \n",
    "# Hit \"Run All:\" no code output\n",
    "# Issues output per Problems panel are import- & definition-related\n",
    "# Next will test code in Terminal, pasting and running line by line\n",
    "# No output or errors in Terminal. To confirm which user, enter below\n",
    "# whoami\n",
    "# Response in Terminal confirms username below\n",
    "# taccstaff\n",
    "# To confirm running the code locally, enter in Terminal as below\n",
    "# uname -a\n",
    "# Response in Terminal confirms local execution as below\n",
    "# Darwin TACCs-MacBook-Pro.local 24.3.0 Darwin Kernel Version 24.3.0: \n",
    "# Thu Jan  2 20:22:00 PST 2025; \n",
    "# root:xnu-11215.81.4~3/RELEASE_X86_64 x86_64\n",
    "\n",
    "# Noticed would be easier to track input of code into Terminal\n",
    "# if code line number were enabled in VS Code, the IDE.\n",
    "# Entered Zen Mode, clicked gear in upper right, enabled \n",
    "# code numbering via clicking Notebook Line Numbers\n",
    "# Noticed creating separate code blocks restarts \n",
    "# code line numbering, creating version control issues\n",
    "# when attempting to reference and track lines of code\n",
    "# Possibly return to move code into one block to renumber\n",
    "# Return to executing code in Terminal\n",
    "# at line of code as reads above\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# Terminal response as below\n",
    "# zsh: command not found: from\n",
    "# Indicates package may not have installed\n",
    "# Aligns with VS Code Problems panel issues about missing imports\n",
    "\n",
    "# As the \"from\" line of code is pulled from the LangChain\n",
    "# signup landing page asking to Set Up Observability (SUO),\n",
    "# and the Set Up Observability step is marked optional\n",
    "# in the UI, next will convert the code inserted from\n",
    "# the Set Up Observability to comments marked with SUO and \n",
    "# will click \"skip\" on the Set Up Observability page\n",
    "# Verified that code sets environment variables to \n",
    "# start logging traces in \"import getpass\" code block above\n",
    "# Ran code in VS Code again to check Problems before \n",
    "# going back to running in Terminal; top field reads as follows\n",
    "# Enter API key for OpenAI: (Press 'Enter' \n",
    "# to confirm or 'Escape' to cancel)\n",
    "\n",
    "# Viewed landing page after clicking skip in SUO step\n",
    "# and see a page with an option to \"Set Up Tracing\"\n",
    "# Consider returning to this page to \"Set Up Tracing\" as a fix if needed\n",
    "\n",
    "# OpenAI API key is referenced in code for \n",
    "# use of OpenAI embeddings model\n",
    "# Thus try changing embeddings model to HuggingFace\n",
    "# Retain previous embeddings model as OpenAI in comments \n",
    "# Add HuggingFace embeddings model above  \n",
    "# Added HuggingFace embeddings model above and \n",
    "# still 13 import langchain Problems\n",
    "# Selected in command panel, Python interpreter & current version\n",
    "# Quit VS Code, reopened & only 4 Problems; \n",
    "# LangChain Problems resolved\n",
    "# 3 Problems are related to vector store selection of AstraDB\n",
    "# Changed vector store to Chroma as it is easy to set up / use\n",
    "# Ran code, only 2 Problems: Import \"bs4\" & \"pip\" not defined\n",
    "# VS Code command panel, cleared cache & reloaded window; didn't fix\n",
    "# Deleted stray \"pip\" to resolve Problem\n",
    "# Noticed BeautifulSoup installation was not part of instructions\n",
    "# Added bs4 install command instruction above to resolve final Problem\n",
    "# Per Mentor, remove use of LangSmith to use unpaid version only\n",
    "# Converted LangSmith code to comment preceded by X in code as above\n",
    "# This step created 10 new issues in the Problem panel\n",
    "# all pertaining to imports could not be resolved\n",
    "# I disabled Pylance extension and all issues in problem panel\n",
    "# that indicated Pylance are now gone\n",
    "# Per Mentor, API in code hints that there is a request \n",
    "# behind a paywall in the code. However, I confirmed that the API\n",
    "# early in the code is to configure a connection between LangChain\n",
    "# and OpenAI thus for now appears necessary. \n",
    "# There have existed several warnings in the code that do not appear\n",
    "# in either the Problem or Debug Console panels\n",
    "# I am next attempting to resolve the following\n",
    "# /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
    "#  warnings.warn(\n",
    "# Since the warning references an API Key when hosting on LangSmith\n",
    "# and I am attempting to get the code to run without any hosting\n",
    "# I found the API key is only for entering a password so will\n",
    "# convert the code to a comment and see if it runs\n",
    "# Still getting warnings within the code about Python frameworks / packages\n",
    "# Next I will create a duplicate file except without comments\n",
    "# That did not resolve the >25 warnings which all reference LocalProtocolError  \n",
    "# Copilot suggested to update dependencies including libraries httpx and httpcore\n",
    "# Started with upgrading pip in the Terminal panel of VS Code as follows\n",
    "# pip install --upgrade pip\n",
    "# Got an error saying something to the effect of global dependencies \n",
    "# may have been affected & did I want to create a container to isolate dependencies\n",
    "# Suspect it is related to APIs and a single issue despite \n",
    "# the many thrown warnings. Per mentor, try AWS chat model\n",
    "# as it appears in the drop-down in the tutorial to be the only\n",
    "# one that does not additionally reference APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document why the rest of the RAG tutorial code does not match\n",
    "# and if it should be marked as an example rather than \n",
    "# a detailed explanation of the code.\n",
    "# If it were simply a detailed explanation of the code,\n",
    "# the code would be identical with perhaps more annotations,\n",
    "# reference links, and / or commentary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
